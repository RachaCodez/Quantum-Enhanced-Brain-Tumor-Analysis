{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Training the Classical Dream Engine (CVAE)\n",
    "\n",
    "This notebook trains a Conditional Variational Autoencoder (CVAE) on BraTS brain tumor MRI data.\n",
    "\n",
    "## What is the CVAE \"Dream Engine\"?\n",
    "\n",
    "The CVAE learns the probability distribution P(segmentation | MRI_image). Given an MRI scan, it can:\n",
    "- Generate multiple plausible tumor segmentations\n",
    "- Capture the inherent uncertainty in tumor boundaries\n",
    "- Create a \"universe of possibilities\" that we'll interrogate with quantum algorithms in Stage 2\n",
    "\n",
    "## Workflow\n",
    "1. Load and visualize BraTS dataset\n",
    "2. Setup CVAE model\n",
    "3. Train the model\n",
    "4. Visualize results\n",
    "5. Generate multiple samples (\"dreams\")\n",
    "6. Analyze uncertainty and clinical properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/classical_model')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from dataset import BraTSDataset, get_dataloaders\n",
    "from cvae import CVAE\n",
    "from train import train, CVAELoss\n",
    "from sampler import CVAESampler\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize BraTS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = BraTSDataset(\n",
    "    images_dir='../data/raw/imagesTr',\n",
    "    labels_dir='../data/raw/labelsTr',\n",
    "    crop_size=(128, 128, 128),\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample\n",
    "def visualize_sample(image, label, slice_idx=64):\n",
    "    \"\"\"\n",
    "    Visualize MRI modalities and segmentation mask\n",
    "    \n",
    "    Args:\n",
    "        image: (4, D, H, W) - 4 modalities\n",
    "        label: (4, D, H, W) - one-hot encoded\n",
    "        slice_idx: Which slice to show\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    modality_names = ['FLAIR', 'T1', 'T1ce', 'T2']\n",
    "    class_names = ['Background', 'Necrotic', 'Edema', 'Enhancing']\n",
    "    \n",
    "    # Show 4 MRI modalities\n",
    "    for i in range(4):\n",
    "        ax = axes[i // 2, i % 2] if i < 2 else axes[0, 2] if i == 2 else axes[1, 0]\n",
    "        ax.imshow(image[i, slice_idx].numpy(), cmap='gray')\n",
    "        ax.set_title(f'{modality_names[i]}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Show segmentation (convert one-hot to class labels)\n",
    "    seg = torch.argmax(label, dim=0)[slice_idx].numpy()\n",
    "    \n",
    "    ax = axes[1, 1]\n",
    "    im = ax.imshow(seg, cmap='tab10', vmin=0, vmax=3)\n",
    "    ax.set_title('Segmentation Mask')\n",
    "    ax.axis('off')\n",
    "    plt.colorbar(im, ax=ax, ticks=[0, 1, 2, 3], label='Class')\n",
    "    \n",
    "    # Overlay on T1ce\n",
    "    ax = axes[1, 2]\n",
    "    ax.imshow(image[2, slice_idx].numpy(), cmap='gray')\n",
    "    masked_seg = np.ma.masked_where(seg == 0, seg)\n",
    "    ax.imshow(masked_seg, cmap='tab10', alpha=0.5, vmin=0, vmax=3)\n",
    "    ax.set_title('T1ce + Segmentation')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize first sample\n",
    "image, label = dataset[0]\n",
    "visualize_sample(image, label, slice_idx=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup CVAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'batch_size': 2,\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 1e-4,\n",
    "    'latent_dim': 256,\n",
    "    'base_channels': 16,\n",
    "    'beta': 0.001,  # KL divergence weight\n",
    "    'crop_size': (128, 128, 128),\n",
    "    'train_split': 0.8,\n",
    "    'num_workers': 4,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for key, val in CONFIG.items():\n",
    "    print(f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    images_dir='../data/raw/imagesTr',\n",
    "    labels_dir='../data/raw/labelsTr',\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    train_split=CONFIG['train_split'],\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    crop_size=CONFIG['crop_size']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CVAE model\n",
    "model = CVAE(\n",
    "    latent_dim=CONFIG['latent_dim'],\n",
    "    base_channels=CONFIG['base_channels']\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model created with {total_params:,} parameters ({total_params * 4 / 1024**2:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "**Note**: Training will take several hours on GPU. For a quick demo, reduce `num_epochs` to 5-10.\n",
    "\n",
    "The model learns:\n",
    "- **Reconstruction**: Generate segmentations that match the ground truth\n",
    "- **Latent structure**: Organize the latent space for easy sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# IMPORTANT: This will take a long time! Consider reducing num_epochs for testing\n",
    "\n",
    "history = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=CONFIG['num_epochs'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    device=device,\n",
    "    beta=CONFIG['beta'],\n",
    "    save_dir='../models'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Total loss\n",
    "ax = axes[0, 0]\n",
    "ax.plot([h['total'] for h in history['train']], label='Train')\n",
    "ax.plot([h['total'] for h in history['val']], label='Val')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Total Loss')\n",
    "ax.set_title('Total Loss')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# Dice score\n",
    "ax = axes[0, 1]\n",
    "ax.plot([h['dice_score'] for h in history['train']], label='Train')\n",
    "ax.plot([h['dice_score'] for h in history['val']], label='Val')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Dice Score')\n",
    "ax.set_title('Dice Score')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# KL Divergence\n",
    "ax = axes[1, 0]\n",
    "ax.plot([h['kl'] for h in history['train']], label='Train')\n",
    "ax.plot([h['kl'] for h in history['val']], label='Val')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('KL Divergence')\n",
    "ax.set_title('KL Divergence')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# Reconstruction loss\n",
    "ax = axes[1, 1]\n",
    "ax.plot([h['recon'] for h in history['train']], label='Train')\n",
    "ax.plot([h['recon'] for h in history['val']], label='Val')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Reconstruction Loss')\n",
    "ax.set_title('Reconstruction Loss')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Samples from the Dream Engine\n",
    "\n",
    "Now the exciting part! Let's use our trained CVAE to generate multiple plausible segmentations for a single MRI scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sampler\n",
    "sampler = CVAESampler(model, device)\n",
    "\n",
    "# Get a test sample\n",
    "test_image, test_label = dataset[10]\n",
    "test_image = test_image.unsqueeze(0).to(device)\n",
    "\n",
    "# Generate multiple samples\n",
    "print(\"Generating samples from the Dream Engine...\")\n",
    "num_samples = 20\n",
    "samples = sampler.generate_samples(test_image, num_samples=num_samples)\n",
    "print(f\"Generated {num_samples} samples!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multiple samples\n",
    "predictions = sampler.get_class_predictions(samples)\n",
    "\n",
    "fig, axes = plt.subplots(4, 5, figsize=(20, 16))\n",
    "slice_idx = 64\n",
    "\n",
    "for i in range(min(20, num_samples)):\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(predictions[i, slice_idx], cmap='tab10', vmin=0, vmax=3)\n",
    "    ax.set_title(f'Sample {i+1}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('20 Different \"Dreams\" of the Tumor Segmentation', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Uncertainty\n",
    "\n",
    "The CVAE captures uncertainty about tumor boundaries. Let's visualize this uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute uncertainty map\n",
    "analysis = sampler.analyze_samples(samples)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Original T1ce image\n",
    "ax = axes[0]\n",
    "ax.imshow(test_image[0, 2, slice_idx].cpu().numpy(), cmap='gray')\n",
    "ax.set_title('T1ce MRI')\n",
    "ax.axis('off')\n",
    "\n",
    "# Ground truth\n",
    "ax = axes[1]\n",
    "gt_seg = torch.argmax(test_label, dim=0)[slice_idx].numpy()\n",
    "ax.imshow(gt_seg, cmap='tab10', vmin=0, vmax=3)\n",
    "ax.set_title('Ground Truth')\n",
    "ax.axis('off')\n",
    "\n",
    "# Uncertainty map\n",
    "ax = axes[2]\n",
    "im = ax.imshow(analysis['uncertainty_map'][slice_idx], cmap='hot')\n",
    "ax.set_title('Uncertainty Map (Entropy)')\n",
    "ax.axis('off')\n",
    "plt.colorbar(im, ax=ax, label='Entropy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHigh uncertainty (red regions) indicates where the model is most uncertain\")\n",
    "print(\"about the tumor boundaries - typically at the edges!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Clinical Analysis: Multifocality\n",
    "\n",
    "A key clinical question: **Is the tumor multifocal (multiple disconnected parts)?**\n",
    "\n",
    "Classical approach: Generate many samples and count.\n",
    "\n",
    "**Quantum approach (Stage 2)**: Use Quantum Amplitude Estimation for quadratic speedup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute multifocal probability\n",
    "multifocal_prob = analysis['multifocal_probability']\n",
    "\n",
    "print(f\"Multifocal Probability: {multifocal_prob:.3f}\")\n",
    "print(f\"\\nInterpretation: {multifocal_prob*100:.1f}% of generated samples show\")\n",
    "print(f\"a tumor with multiple disconnected components.\")\n",
    "print(f\"\\nThis is a clinically actionable uncertainty metric!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "volume_keys = ['necrotic', 'edema', 'enhancing', 'total']\n",
    "titles = ['Necrotic Core', 'Edema', 'Enhancing Tumor', 'Total Tumor']\n",
    "\n",
    "for i, (key, title) in enumerate(zip(volume_keys, titles)):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    volumes = analysis['volumes'][key]\n",
    "    ax.hist(volumes, bins=20, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(volumes.mean(), color='red', linestyle='--', label=f'Mean: {volumes.mean():.0f}')\n",
    "    ax.set_xlabel('Volume (voxels)')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'{title} Volume Distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "### What We Built:\n",
    "1. **CVAE \"Dream Engine\"**: Generates multiple plausible tumor segmentations\n",
    "2. **Uncertainty Quantification**: Maps out where the model is uncertain\n",
    "3. **Clinical Metrics**: Computes actionable probabilities (e.g., multifocality)\n",
    "\n",
    "### Next Steps (Stage 2):\n",
    "Now that we have our \"universe of possibilities\", we'll use **Quantum Amplitude Estimation (QAE)** to:\n",
    "- Load all samples into a quantum superposition\n",
    "- Query clinical properties with quadratic speedup\n",
    "- Demonstrate the hybrid quantum-classical advantage!\n",
    "\n",
    "### Key Files Created:\n",
    "- `dataset.py`: BraTS data loading and preprocessing\n",
    "- `cvae.py`: CVAE architecture\n",
    "- `train.py`: Training loop and loss functions\n",
    "- `sampler.py`: Sampling and analysis utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[SUCCESS] Stage 1 Complete!\")\n",
    "print(\"\\nThe Classical Dream Engine is ready.\")\n",
    "print(\"Proceed to Stage 2: Quantum Interrogation with QAE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
